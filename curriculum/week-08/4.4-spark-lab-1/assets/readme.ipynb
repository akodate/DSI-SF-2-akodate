{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Spark Lab 1\n",
    "type: lab\n",
    "duration: \"1:25\"\n",
    "creator:\n",
    "    name: Francesco Mosconi\n",
    "    city: SF\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Spark Lab 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this lab we will use Spark to process the Bikeshare data. We will explore both the streaming and the sql APIs for Spark in order to investigate bike share usage habits in the Bay Area.\n",
    "\n",
    "We will do that on the Virtual Machine we have created on the first day. So the first steps to get started are:\n",
    "    \n",
    "    cd dsi-bigdata-vm\n",
    "    vagrant up\n",
    "    vagrant ssh\n",
    "\n",
    "And then, once inside, run:\n",
    "\n",
    "    spark_local_start.sh\n",
    "\n",
    "**Important:** If your machine is already running and you've started the Hadoop services with `bigdata_start.sh`, you may want to first run `bigdata_stop.sh` to stop all services and free some memory space.\n",
    "\n",
    "Once you've started spark in local mode, you should be able to access Jupyter at this address:\n",
    "\n",
    "http://10.211.55.101:18888\n",
    "\n",
    "In order to run the starter code on the VM, you will need to upload it using the Jupyter browser upload function.\n",
    "\n",
    "![](./assets/images/upload.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "- parse data: split csv lines\n",
    "- filter: for Caltrain station\n",
    "- Spark Map Reduce: Find out number of trips per hour and per day\n",
    "    - trips by day - hour (mapper)\n",
    "    - trips by day - hour (reducer)\n",
    "- Spark Map Reduce: Find out number of trips per hour\n",
    "    - trips by hour (mapper)\n",
    "    - trips by hour (reducer)\n",
    "- collect\n",
    "\n",
    "**Bonus:**\n",
    "Repeat the task using Spark SQL\n",
    "\n",
    "#### Starter code\n",
    "\n",
    "[Starter Code](./assets/code/starter-code/starter-code.ipynb)\n",
    "> [Solution Code](./assets/code/solution-code/solution-code.ipynb)\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Spark CSV](https://github.com/databricks/spark-csv)\n",
    "- [Pyspark programming guide](https://spark.apache.org/docs/0.9.0/python-programming-guide.html)\n",
    "- [Download and run Spark](https://github.com/mahmoudparsian/pyspark-tutorial/blob/master/howto/download_install_run_spark.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
