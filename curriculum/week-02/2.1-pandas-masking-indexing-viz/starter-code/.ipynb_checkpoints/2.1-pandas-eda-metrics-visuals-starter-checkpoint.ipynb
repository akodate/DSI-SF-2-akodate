{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization and EDA metrics with pandas\n",
    "\n",
    "In this lesson we will be using a boston housing market dataset. The columns of the dataset are coded as so:\n",
    "\n",
    "    CRIM: per capita crime rate by town \n",
    "    ZN: proportion of residential land zoned for lots over 25,000 sq.ft. \n",
    "    INDUS: proportion of non-retail business acres per town \n",
    "    CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) \n",
    "    NOX: nitric oxides concentration (parts per 10 million) \n",
    "    RM: average number of rooms per dwelling \n",
    "    AGE: proportion of owner-occupied units built prior to 1940 \n",
    "    DIS: weighted distances to five Boston employment centres \n",
    "    RAD: index of accessibility to radial highways \n",
    "    TAX: full-value property-tax rate per 10000 dollars\n",
    "    PTRATIO: pupil-teacher ratio by town \n",
    "    B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town \n",
    "    LSTAT: % lower status of the population \n",
    "    MEDV: Median value of owner-occupied homes in 1000's of dollars\n",
    "    \n",
    "Each row in the dataset is for a different suburb of Boston.\n",
    "\n",
    "These descriptions of shortened or coded variables are often described as \"codebooks\", or data dictionaries. They are the often found alongside datasets you might find online.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Load packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "boston_file = '/Users/alex/Desktop/DSI-SF-2/datasets/boston_housing_data/housing.csv'\n",
    "boston = pd.read_csv(boston_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Describe the basic format and variables in the data:\n",
    "\n",
    "As you recall, you can use `.head()` (and optionally pass in an integer for the number of rows you want to see) to examine what the loaded data looks like.\n",
    "\n",
    "The `.describe()` function will give you summary statistics for each of your variables.\n",
    "\n",
    "The numeric data in columns has been **pre-cleaned** for you for the sake of focusing the lesson on other things (no corrupt data or string values that need to be converted to numeric). This is rarely the case in reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0        CRIM          ZN       INDUS        CHAS         NOX  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean   253.500000    3.613524   11.363636   11.136779    0.069170    0.554695   \n",
      "std    146.213884    8.601545   23.322453    6.860353    0.253994    0.115878   \n",
      "min      1.000000    0.006320    0.000000    0.460000    0.000000    0.385000   \n",
      "25%    127.250000    0.082045    0.000000    5.190000    0.000000    0.449000   \n",
      "50%    253.500000    0.256510    0.000000    9.690000    0.000000    0.538000   \n",
      "75%    379.750000    3.677082   12.500000   18.100000    0.000000    0.624000   \n",
      "max    506.000000   88.976200  100.000000   27.740000    1.000000    0.871000   \n",
      "\n",
      "               RM         AGE         DIS         RAD         TAX     PTRATIO  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean     6.284634   68.574901    3.795043    9.549407  408.237154   18.455534   \n",
      "std      0.702617   28.148861    2.105710    8.707259  168.537116    2.164946   \n",
      "min      3.561000    2.900000    1.129600    1.000000  187.000000   12.600000   \n",
      "25%      5.885500   45.025000    2.100175    4.000000  279.000000   17.400000   \n",
      "50%      6.208500   77.500000    3.207450    5.000000  330.000000   19.050000   \n",
      "75%      6.623500   94.075000    5.188425   24.000000  666.000000   20.200000   \n",
      "max      8.780000  100.000000   12.126500   24.000000  711.000000   22.000000   \n",
      "\n",
      "                B       LSTAT        MEDV  \n",
      "count  506.000000  506.000000  506.000000  \n",
      "mean   356.674032   12.653063   22.532806  \n",
      "std     91.294864    7.141062    9.197104  \n",
      "min      0.320000    1.730000    5.000000  \n",
      "25%    375.377500    6.950000   17.025000  \n",
      "50%    391.440000   11.360000   21.200000  \n",
      "75%    396.225000   16.955000   25.000000  \n",
      "max    396.900000   37.970000   50.000000  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  \\\n",
       "0           1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1   \n",
       "1           2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2   \n",
       "2           3  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2   \n",
       "3           4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3   \n",
       "4           5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3   \n",
       "\n",
       "   TAX  PTRATIO       B  LSTAT  MEDV  \n",
       "0  296     15.3  396.90   4.98  24.0  \n",
       "1  242     17.8  396.90   9.14  21.6  \n",
       "2  242     17.8  392.83   4.03  34.7  \n",
       "3  222     18.7  394.63   2.94  33.4  \n",
       "4  222     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the first 4 rows:\n",
    "print boston.describe()\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unwanted columns:\n",
    "\n",
    "The `.read_csv()` function has added a column called `Unnamed: 0`, which appears to be just the number of the rows. We already have the number id of the rows in the DataFrame's index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print out the index object and the first 20 items in the DataFrame's index \n",
    "# to see that we have these row numbers already:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the unneccesary column:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the column names more descriptive\n",
    "\n",
    "The codes are fine for some people, but I don't like having to memorize or reference the codebook whenever I want to know the meaning of a variable.\n",
    "\n",
    "There is more than one way to do this. I am going to use the explicit `.rename()` function.\n",
    "\n",
    "    CRIM: per capita crime rate by town \n",
    "    ZN: proportion of residential land zoned for lots over 25,000 sq.ft. \n",
    "    INDUS: proportion of non-retail business acres per town \n",
    "    CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) \n",
    "    NOX: nitric oxides concentration (parts per 10 million) \n",
    "    RM: average number of rooms per dwelling \n",
    "    AGE: proportion of owner-occupied units built prior to 1940 \n",
    "    DIS: weighted distances to five Boston employment centres \n",
    "    RAD: index of accessibility to radial highways \n",
    "    TAX: full-value property-tax rate per 10000 dollars\n",
    "    PTRATIO: pupil-teacher ratio by town \n",
    "    B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town \n",
    "    LSTAT: % lower status of the population \n",
    "    MEDV: Median value of owner-occupied homes in 1000's of dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe the variables\n",
    "\n",
    "Use the `.describe()` function here. What are some, if any, oddities you notice about the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some potential outliers in variables here:\n",
    "\n",
    "1. black_stat has at least one outlier at the min end of the range.\n",
    "2. owner_occup_pct has at least one outlier at the min end.\n",
    "3. business_zone_pct might have an outlier at the min end.\n",
    "4. rate_of_crime has at least one outlier at the max end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Plot variables with potential outliers using seaborn boxplots.\n",
    "\n",
    "Some notes on seaborn's boxplot keyword argument options that I'm going to use:\n",
    "\n",
    "    orient: can be 'v' or 'h' for vertical and horizontal, respectively\n",
    "    fliersize: the size of the outlier points (pixels I think)\n",
    "    linewidth: the width of line outlining the boxplot\n",
    "    notch: show the confidence interval for the median (calculated by seaborn/plt.boxplot)\n",
    "    saturation: saturate the colors to an extent\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rate of crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# percent owner occupied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# business zone percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# black population statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the boxplots, it looks like rate of crime and the proportion black people statistic have real outliers. The other variables actually look OK to me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Plot all the variables on boxplots together.\n",
    "\n",
    "Let's try this first with the variables as they are, using a horizontal boxplot with seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boxplots are hard to visualize since all of these variables are on different scales.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Rescaling variables and plotting again.\n",
    "\n",
    "Rescaling of variables is very common, and in fact when we get to regularization in models during upcoming weeks the rescaling procedure is actually going to become essential for the regularization to work.\n",
    "\n",
    "Let's rescale the variables using a procedure called \"standardization\" or alternatively \"normalization\".\n",
    "\n",
    "Normalization is a concise process:\n",
    "\n",
    "    normalized_variable = (variable - mean_of_variable) / std_dev_of_variable\n",
    "    \n",
    "What does this do, exactly? It forces the variable's values to have a mean of 0 and a standard deviation of 1. Nothing else is changed about the distribution of the variable. It doesn't become \"normal\" or anything. \n",
    "\n",
    "### 5.1 Extract rate of crime and plot the distribution \n",
    "\n",
    "Also print out the mean and standard deviation of the original variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the rate_of_crime variable and plot again. Notice the new mean is centered at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the normalized variable with outliers removed. Let's set the criteria for outliers to be any values that are above 4 * the std_dev of the variable (which is now just 4, since we have forced the standard deviation to be 1 through normalization!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable is still extremely skewed. Dealing with this is a more difficult issue and we will explore this at a later time! (One of your challege/expert problems in Project 2 teaches one method to try and deal with skewness in a variable – keep in mind, however, no method to get rid of skewness is perfect.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Normalize all the variables and plot the full boxplot again.\n",
    "\n",
    "Pandas DataFrames actually make it extremely easy to normalize columns all at once. Say we have a DataFrame `data`, then we can normalize all the columns like so:\n",
    "\n",
    "    data_norm = (data_norm - data_norm.mean()) / data_norm.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Covariance and correlation of variables\n",
    "\n",
    "A great way to immediately get a feel for relationships between your variables is with a correlation matrix.\n",
    "\n",
    "Let's first examine the covariance and the correlation and calculate these by hand.\n",
    "\n",
    "### 6.1 Covariance of variables\n",
    "\n",
    "Given sample size $N$ variables $X$ and $Y$, with means $\\bar{X}$ and $\\bar{Y}$:\n",
    "\n",
    "### $$ \\text{covariance}(X, Y) = \\sum_{i=1}^N \\frac{(X - \\bar{X})(Y - \\bar{Y})}{N}$$\n",
    "\n",
    "The covariance is a measure of \"relatedness\" between variables. It is literally the sum of deviations from the mean of $X$ times deviations from the mean of $Y$ adjusted by the sample size $N$.\n",
    "\n",
    "Code the covariance between `pct_underclass` and `home_median_value` below by hand. Verify that you got the correct result using `np.cov()`. Set the keyword argument `bias=True` in `np.cov()` to have it use the same covariance calculation.\n",
    "\n",
    "Note: `np.cov` returns a covariance _matrix_, which will be each values covariance with itself and the other variable in matrix format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Correlation of variables\n",
    "\n",
    "What's the problem with covariance? Well, its not very interpretable. The values are difficult to read because they are relative to the variance of the variables.\n",
    "\n",
    "A much more common metric, and one easily calculable from the covariance, is the correlation.\n",
    "\n",
    "Again, let $X$ and $Y$ be our two variables, with covariance $cov(X, Y)$ that we calculated above:\n",
    "\n",
    "### $$ \\text{pearson correlation}\\;r = cor(X, Y) =\\frac{cov(X, Y)}{std(X)std(Y)}$$\n",
    "\n",
    "What the pearson correlation does is in fact directly related to what we did above during the normalization procedure. We are taking the covariance and dividing it by the product of the standard deviations of X and Y. This adjusts the value we get out by the variance of the variables so that $r$ must fall between -1 and 1.\n",
    "\n",
    "Calculate the correlation between `pct_under` and `med_value` by hand below. Check that it is the same as `np.corrcoef()` with `bias=True`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 The correlation matrix\n",
    "\n",
    "We can see the correlation between all the numeric variables in our dataset by using pandas DataFrame's built in `.corr()` function. Use it below on the boston dataset.\n",
    "\n",
    "It is very useful to get a feel for what is related and what is not, which can help you decide what is worth investigating further (though with a lot of variables, the matrix can be a bit overwhelming...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Scatterplots\n",
    "\n",
    "Choose two variables that appear very related and two variables that appear to be unrelated.\n",
    "\n",
    "Use seaborns `regplot` to plot a scatter plot between the pairs of variables. `regplot` will also plot a regression line by default – we will go into regressions next week. They are, as you might expect, very related to correlations. You can turn this off with `fit_reg=False` if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
