{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs and SQL Joins Lab\n",
    "\n",
    "The city of San Francisco wants to assess the quality of restaurants in the city. Their data is scattered across multiple sources and incomplete.\n",
    "\n",
    "They tasked you to help them assess it.\n",
    "\n",
    "They would like to know what the most common violations are where they happen most frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial data inspection\n",
    "\n",
    "To answer the question we will need to retrieve and merge data from multiple files.\n",
    "\n",
    "Yelp provides data on food quality, that can be found at [this address](http://www.yelp.com/healthscores/feeds). We already downloaded 4 files that you can find in the [assets folder](../../assets/datasets/yelp/).\n",
    "\n",
    "In the bonus part we will also use the Google Geocoding API and data on [Neighborhoods](https://www.google.com/fusiontables/DataSource?docid=1zNwsvTwj-dH0QxuuDrKFsyfNklajd7WwEyaZ2U9M#rows:id=1).\n",
    "\n",
    "1. Open each of the files and inspect them visually\n",
    "- What information do they contain?\n",
    "> They contain information on SF businesses, inspections, legend violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls ../../assets/datasets/yelp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Local database\n",
    "\n",
    "The first step in our analysis is to import the data into a local PostgreSQL database.\n",
    "\n",
    "1. Connect to a local Postgres database and import the files to separate tables.\n",
    "\n",
    "**Hint:** The files are probably not encoded in utf8 and this could create a problem when importing the data into postgres. You can read more about encodings here: http://www.postgresql.org/docs/current/interactive/multibyte.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgresql://<user>:@localhost:5432/inspections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_to_sql(name):\n",
    "    df = pd.read_csv('../../assets/datasets/yelp/{}.csv'.format(name), encoding='latin1')\n",
    "    df.to_sql(name, engine, flavor='postgres', if_exists='replace')\n",
    "    print \"done\", name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_to_sql('businesses')\n",
    "load_to_sql('inspections')\n",
    "load_to_sql('legend')\n",
    "load_to_sql('violations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b Display the first few lines of each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql postgresql://<user>@localhost:5432/inspections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from inspections limit 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from businesses limit 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from violations limit 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from legend limit 2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.b Investigate violations\n",
    "\n",
    "Let's focus on the violations table initially.\n",
    "\n",
    "\n",
    "Answer these questions using sql:\n",
    "1. How many violations are there?\n",
    "- How many businesses committing violations?\n",
    "- What's the average number of violations per business?\n",
    "\n",
    "Answer these questions using python\n",
    "1. Draw a plot of the violations count\n",
    "- Is the average number of violations meaningful?\n",
    "> Not really, the distribution is quite skewed\n",
    "- draw a plot of the normalized cumulative violation counts. Can we discard the restaurants with few violations?\n",
    "- where would you draw a threshold if you were to keep 90% of the violations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select count(*) from violations;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select count(distinct business_id)\n",
    "from violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select business_id, count(*) as count\n",
    "from violations\n",
    "group by business_id\n",
    "order by count desc\n",
    "limit 20;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select avg(count)\n",
    "from (\n",
    "    select business_id, count(*) as count\n",
    "    from violations\n",
    "    group by business_id\n",
    "    ) as v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "violations_per_biz = pd.read_sql_query(\"\"\"\n",
    "select business_id, count(*) as count\n",
    "from violations\n",
    "group by business_id\n",
    "order by count desc\n",
    "\"\"\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "violations_per_biz['count'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "violations_per_biz['count'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(violations_per_biz['count'].cumsum()/violations_per_biz['count'].sum()).plot()\n",
    "plt.axhline(0.9, color = 'r')\n",
    "plt.axvline(3500, color = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> we capture about 90% of the violations by considering restaurants with 5 or more violations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.c Investigate Inspections\n",
    "\n",
    "In the previous step we looked at violations count. However we also have an inspection score available in the inspections table. Let's have a look at that too.\n",
    "\n",
    "Answer these questions using SQL:\n",
    "1. What's the average score for the whole city?\n",
    "- What's the average score per business?\n",
    "- Does the score correlate with the number of inspections?\n",
    "- Create a dataframe from a table with the following columns:\n",
    "    business_id, average_score, number_of_inspections, number_of_violations\n",
    "- Use pandas to do a scatter matrix plot of average_score, number_of_inspections, number_of_violations to check for correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select avg(score)\n",
    "from inspections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volations_inspections = pd.read_sql_query(\"\"\"\n",
    "select a.business_id, average_score, number_of_inspections, number_of_violations\n",
    "from \n",
    "(select business_id, avg(score) as average_score, count(*) as number_of_inspections\n",
    "from inspections\n",
    "group by business_id) A\n",
    "join\n",
    "(select business_id, count(*) as number_of_violations\n",
    "from violations\n",
    "group by business_id) B\n",
    "on A.business_id = B.business_id;\n",
    "\"\"\", engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volations_inspections.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = scatter_matrix(volations_inspections, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Negative score is clearly correlated with number of violations, while it's not clear if a higher number of inspections leads to lower score or higher number of violations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Zipcode analysis\n",
    "\n",
    "The town administration would like to know which zip code are the ones where they should focus the inspections.\n",
    "\n",
    "Use the information contained in the `businesses` table as well as the previous tables to answer the following questions using SQL:\n",
    "\n",
    "1. Count the number of businesses per zipcode and sort them by descending order\n",
    "- Which are the top 5 zipcodes with the worst average score?\n",
    "    - Restrict your analysis to the zipcodes with at least 50 businesses\n",
    "    - Do a simple average of the inspections scores in the postal code\n",
    "- Which are the top 5 zipcodes with the highest number of violations per restaurant?\n",
    "    - Restrict your  analysis to the zipcodes with at least 50 businesses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select postal_code, count(distinct business_id)\n",
    "from businesses\n",
    "group by postal_code\n",
    "order by count desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "select postal_code, avg(score) as avg_score, count(distinct b.business_id) as count\n",
    "from businesses b\n",
    "join inspections i\n",
    "on b.business_id = i.business_id\n",
    "group by postal_code\n",
    "having count(distinct b.business_id) > 50\n",
    "order by avg_score\n",
    "limit 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "select postal_code,  1.0*count(v.business_id) / count(distinct b.business_id) as viol_per_rest\n",
    "from businesses b\n",
    "join violations v\n",
    "on b.business_id = v.business_id\n",
    "group by postal_code\n",
    "having count(distinct b.business_id) > 50\n",
    "order by viol_per_rest desc\n",
    "limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final recommendation\n",
    "Give a final recommendation on which 2 zipcodes should the administration focus and choose an appropriate plot to convince them visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volations_inspections_postal = pd.read_sql_query(\"\"\"\n",
    "select a.business_id, average_score, number_of_inspections, number_of_violations, postal_code\n",
    "from \n",
    "(select business_id, avg(score) as average_score, count(*) as number_of_inspections\n",
    "from inspections\n",
    "group by business_id) A\n",
    "join\n",
    "(select business_id, count(*) as number_of_violations\n",
    "from violations\n",
    "group by business_id) B\n",
    "on A.business_id = B.business_id\n",
    "join businesses C\n",
    "on A.business_id = C.business_id\n",
    "\"\"\", engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volations_inspections_postal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top2idx = (volations_inspections_postal['postal_code'] == '94133') | \\\n",
    "          (volations_inspections_postal['postal_code'] == '94122')\n",
    "top2 = volations_inspections_postal[top2idx]\n",
    "others = volations_inspections_postal[~top2idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "others['average_score'].hist(normed=True, alpha=0.5)\n",
    "top2['average_score'].hist(normed=True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "others['number_of_violations'].hist(normed=True, alpha=0.5)\n",
    "top2['number_of_violations'].hist(normed=True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bonus: Neighborhood data\n",
    "\n",
    "Instead of looking at zipcodes we may be interested in using Neighborhood names.\n",
    "\n",
    "It's beyond the scope of this lab to do a proper introduction to Geocoding and Reverse Geocoding, but we will give some pointers for further exploration.\n",
    "\n",
    "## 1. Google Geocoding API\n",
    "Have a look at:\n",
    "- https://developers.google.com/maps/documentation/geocoding/intro\n",
    "- https://maps.googleapis.com/maps/api/geocode/json?address=\n",
    "- https://maps.googleapis.com/maps/api/geocode/json?latlng=\n",
    "\n",
    "Through this API you can retrieve an address or a neighborhood from a lat-lon pair (reverse geocoding), or you can retrieve lat long and other information from an address (geocoding).\n",
    "\n",
    "1. Try experimenting with and retrieving a few addresses\n",
    "- Note that google imposes limits on the number of free queries\n",
    "- How many missing lat-lon pairs do we have?\n",
    "> about half of the data ~(3k) have no lat-lon pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biz = pd.read_sql('select * from businesses;', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biz.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biz.name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_geocode_str(address_list):\n",
    "    try:\n",
    "        address = ' '.join(address_list)\n",
    "    except:\n",
    "        address = None\n",
    "    return address\n",
    "    \n",
    "testgeo = biz[['address', 'city', 'state']].head(1).apply(to_geocode_str, axis=1).values[0]\n",
    "testgeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib import urlencode\n",
    "\n",
    "BASE_URI = 'https://maps.googleapis.com/maps/api/geocode/json'\n",
    "\n",
    "def build_url(params):\n",
    "    \n",
    "#         default_params = {'key': 'AIzaSyCYadFJSe2RNgaa47eURwwsMT0RJNv4zUg'}\n",
    "\n",
    "    query_params = dict(\n",
    "        list(params.items()) # + list(default_params.items())\n",
    "    )\n",
    "    query_params = urlencode(query_params)\n",
    "    url = '{base}?{params}'.format(base=BASE_URI, params=query_params)\n",
    "    return url\n",
    "    \n",
    "build_url({'address': testgeo})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testgeos = biz[['address', 'city', 'state']].apply(to_geocode_str, axis=1).values\n",
    "testgeos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 2\n",
    "The pycurl library seems to be faster than requests in getting information from the google api.\n",
    "\n",
    "1. See if you can extract the neighborhood from an address using the geocode api and a bit of json parsing\n",
    "- Note that you would surely hit the daily limit if you pulled each address' neighborhood from the api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pycurl\n",
    "import certifi\n",
    "from StringIO import StringIO\n",
    "\n",
    "def get_geocode_from_url(url):\n",
    "    buffer = StringIO()\n",
    "    c = pycurl.Curl()\n",
    "    c.setopt(pycurl.CAINFO, certifi.where())\n",
    "    c.setopt(c.URL, url)\n",
    "    c.setopt(c.WRITEDATA, buffer)\n",
    "    c.perform()\n",
    "    c.close()\n",
    "\n",
    "    body = buffer.getvalue()\n",
    "    return body\n",
    "\n",
    "body = get_geocode_from_url('https://maps.googleapis.com/maps/api/geocode/json?address=033+BELDEN+PL+San+Francisco+CA')\n",
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ujson as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_hood(body):\n",
    "    d = json.loads(body)\n",
    "    first_res = d['results'][0]\n",
    "    addr_list = first_res['address_components']\n",
    "    for c in addr_list:\n",
    "        if 'neighborhood' in c['types']:\n",
    "            return c['short_name']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extract_hood(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 3\n",
    "We can find the neighborhood using the polygons associated to each of them.\n",
    "[Here](https://www.google.com/fusiontables/DataSource?docid=1zNwsvTwj-dH0QxuuDrKFsyfNklajd7WwEyaZ2U9M#rows:id=1) you can find these polygons (and we also copied them [locally](../../assets/datasets/sfneighborhoods.csv).\n",
    "\n",
    "[This article](http://streamhacker.com/2010/03/23/python-point-in-polygon-shapely/) describes how to use the shapely package to check if a point belongs to a polygon.\n",
    "\n",
    "1. See if you can build a function that retrieves the neighborhood for a given address using the polygon data\n",
    "- Count the number of businesses in each neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hoods = pd.read_csv('../../assets/datasets/sfneighborhoods.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hoods.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hoods['Polygon'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boundaries = re.findall('(-?\\w+\\.\\w+),(-?\\w+\\.\\w+),-?\\w+\\.\\w+', hoods['Polygon'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coords = [map(float, i) for i in boundaries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import MultiPoint\n",
    "poly = MultiPoint(coords).convex_hull\n",
    "\n",
    "from shapely.geometry import Point\n",
    "point = Point([-122.5, 37.775429])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poly.contains(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_multipoint(ps):\n",
    "    boundaries = re.findall('(-?\\w+\\.\\w+),(-?\\w+\\.\\w+),-?\\w+\\.\\w+', ps)\n",
    "    coords = [map(float, i) for i in boundaries]\n",
    "    return MultiPoint(coords).convex_hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hoods['Multipoint'] = hoods['Polygon'].apply(build_multipoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biz['point'] = biz[['longitude','latitude']].apply(Point, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biz.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_hood(point):\n",
    "    try:\n",
    "        hood = hoods[hoods['Multipoint'].apply(lambda x:x.contains(point))]['Neighborhood'].values[0]\n",
    "    except:\n",
    "        hood = None\n",
    "    return hood\n",
    "\n",
    "get_hood(biz.loc[0, 'point'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biz['hood'] = biz['point'].apply(get_hood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# biz['hood'].value_counts().to_csv('../../../5.2-lesson/assets/datasets/violations/neighborhoods_biz_count.csv')\n",
    "biz['hood'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further exploration\n",
    "\n",
    "Postgres is actually GIS enabled, so we could do location based queries directly in the database.\n",
    "\n",
    "Have a look at http://postgis.refractions.net/ for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to export hood coords for 5.2-lesson\n",
    "# coords = []\n",
    "# for n, r in hoods.iterrows():\n",
    "#     ps = r['Polygon']\n",
    "#     h =  r['Neighborhood']\n",
    "#     boundaries = re.findall('(-?\\w+\\.\\w+),(-?\\w+\\.\\w+),-?\\w+\\.\\w+', ps)\n",
    "#     for i in xrange(len(boundaries)):\n",
    "#         b = boundaries[i]\n",
    "#         if i == 0:\n",
    "#             coords.append([h, 'START', float(b[1]), float(b[0]), i+1, n+1])\n",
    "#         else:\n",
    "#             coords.append([h, 'INTERIOR', float(b[1]), float(b[0]), i+1, n+1])\n",
    "            \n",
    "# hoodcoords = pd.DataFrame(coords, columns = ['NEIGHBORHOOD', 'VERTEX TYPE',\n",
    "#                                              'LATITUDE', 'LONGITUDE',\n",
    "#                                              'POINTORDER', 'POLYGON NUMBER'])\n",
    "#\n",
    "# hoodcoords.to_csv('../../../5.2-lesson/assets/datasets/violations/neighborhoods_coordinates.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
