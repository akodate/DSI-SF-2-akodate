{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs and SQL Joins Lab\n",
    "\n",
    "The city of San Francisco wants to assess the quality of restaurants in the city. Their data is scattered across multiple sources and incomplete.\n",
    "\n",
    "They tasked you to help them assess it.\n",
    "\n",
    "They would like to know what the most common violations are where they happen most frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial data inspection\n",
    "\n",
    "To answer the question we will need to retrieve and merge data from multiple files.\n",
    "\n",
    "Yelp provides data on food quality, that can be found at [this address](http://www.yelp.com/healthscores/feeds). We already downloaded 4 files that you can find in the [assets folder](../../assets/datasets/yelp/).\n",
    "\n",
    "In the bonus part we will also use the Google Geocoding API and data on [Neighborhoods](https://www.google.com/fusiontables/DataSource?docid=1zNwsvTwj-dH0QxuuDrKFsyfNklajd7WwEyaZ2U9M#rows:id=1).\n",
    "\n",
    "1. Open each of the files and inspect them visually\n",
    "- What information do they contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls ../../assets/datasets/yelp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Local database\n",
    "\n",
    "The first step in our analysis is to import the data into a local PostgreSQL database.\n",
    "\n",
    "1. Connect to a local Postgres database and import the files to separate tables.\n",
    "\n",
    "**Hint:** The files are probably not encoded in utf8 and this could create a problem when importing the data into postgres. You can read more about encodings here: http://www.postgresql.org/docs/current/interactive/multibyte.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b Display the first few lines of each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.b Investigate violations\n",
    "\n",
    "Let's focus on the violations table initially.\n",
    "\n",
    "\n",
    "Answer these questions using sql:\n",
    "1. How many violations are there?\n",
    "- How many businesses committing violations?\n",
    "- What's the average number of violations per business?\n",
    "\n",
    "Answer these questions using python\n",
    "1. Draw a plot of the violations count\n",
    "- Is the average number of violations meaningful?\n",
    "- Draw a plot of the normalized cumulative violation counts. Can we discard the restaurants with few violations?\n",
    "- Where would you draw a threshold if you were to keep 90% of the violations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.c Investigate Inspections\n",
    "\n",
    "In the previous step we looked at violations count. However we also have an inspection score available in the inspections table. Let's have a look at that too.\n",
    "\n",
    "Answer these questions using SQL:\n",
    "1. What's the average score for the whole city?\n",
    "1. What's the average score per business?\n",
    "- Does the score correlate with the number of inspections?\n",
    "- Create a dataframe from a table with the following columns:\n",
    "    business_id, average_score, number_of_inspections, number_of_violations\n",
    "- Use pandas to do a scatter matrix plot of average_score, number_of_inspections, number_of_violations to check for correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Zipcode analysis\n",
    "\n",
    "The town administration would like to know which zip code are the ones where they should focus the inspections.\n",
    "\n",
    "Use the information contained in the `businesses` table as well as the previous tables to answer the following questions using SQL:\n",
    "\n",
    "1. Count the number of businesses per zipcode and sort them by descending order\n",
    "- Which are the top 5 zipcodes with the worst average score?\n",
    "    - restrict your analysis to the zipcodes with at least 50 businesses\n",
    "    - do a simple average of the inspections scores in the postal code\n",
    "- Which are the top 5 zipcodes with the highest number of violations per restaurant?\n",
    "    - restrict your  analysis to the zipcodes with at least 50 businesses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final recommendation\n",
    "Give a final recommendation on which 2 zipcodes should the administration focus and choose an appropriate plot to convince them visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bonus: Neighborhood data\n",
    "\n",
    "Instead of looking at zipcodes we may be interested in using Neighborhood names.\n",
    "\n",
    "It's beyond the scope of this lab to do a proper introduction to Geocoding and Reverse Geocoding, but we will give some pointers for further exploration.\n",
    "\n",
    "### 1. Google Geocoding API\n",
    "Have a look at:\n",
    "- https://developers.google.com/maps/documentation/geocoding/intro\n",
    "- https://maps.googleapis.com/maps/api/geocode/json?address=\n",
    "- https://maps.googleapis.com/maps/api/geocode/json?latlng=\n",
    "\n",
    "Through this API you can retrieve an address or a neighborhood from a lat-lon pair (reverse geocoding), or you can retrieve lat long and other information from an address (geocoding).\n",
    "\n",
    "1. Try experimenting with and retrieving a few addresses\n",
    "- Note that google imposes limits on the number of free queries\n",
    "- How many missing lat-lon pairs do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 2\n",
    "The pycurl library seems to be faster than requests in getting information from the google api.\n",
    "\n",
    "1. See if you can extract the neighborhood from an address using the geocode api and a bit of json parsing\n",
    "- Note that you would surely hit the daily limit if you pulled each address' neighborhood from the api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 3\n",
    "We can find the neighborhood using the polygons associated to each of them.\n",
    "[Here](https://www.google.com/fusiontables/DataSource?docid=1zNwsvTwj-dH0QxuuDrKFsyfNklajd7WwEyaZ2U9M#rows:id=1) you can find these polygons (and we also copied them [locally](../../assets/datasets/sfneighborhoods.csv).\n",
    "\n",
    "[This article](http://streamhacker.com/2010/03/23/python-point-in-polygon-shapely/) describes how to use the shapely package to check if a point belongs to a polygon.\n",
    "\n",
    "- See if you can build a function that retrieves the neighborhood for a given address using the polygon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further exploration\n",
    "\n",
    "Postgres is actually GIS enabled, so we could do location based queries directly in the database.\n",
    "\n",
    "Have a look at http://postgis.refractions.net/ for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
