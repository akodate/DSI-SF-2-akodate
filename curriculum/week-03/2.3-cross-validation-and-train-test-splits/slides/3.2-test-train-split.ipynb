{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png\" style=\"float:  left; margin: 10px;\">\n",
    "\n",
    "# Test / Train / Split\n",
    "---\n",
    "Week 3 | Lesson 3.2\n",
    "\n",
    "### LEARNING OBJECTIVES\n",
    "*After this lesson, you will be able to:*\n",
    "- Split data into testing and training sets\n",
    "- Perform cross validation scoring\n",
    "- Make cross validation predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### STUDENT PRE-WORK\n",
    "*Before this lesson, you should already be able to:*\n",
    "- Fit a linear model to a dataframe\n",
    "- Basic use of sci-kit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LESSON GUIDE\n",
    "| TIMING  | TYPE  | TOPIC  |\n",
    "|:-:|---|---|\n",
    "| 5 min  | [Opening](#opening)  | Topic description  |\n",
    "| 10 min  | [Introduction](#introduction)   | Topic description  |\n",
    "| 15 min  | [Demo](#demo)  | Topic description  |\n",
    "| 25 min  | [Guided Practice](#guided-practice<a name=\"opening\"></a>)  | Topic description  |\n",
    "| 25 min  | [Independent Practice](#ind-practice)  | Topic description  |\n",
    "| 5 min  | [Conclusion](#conclusion)  | Topic description  |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://tomrobertshaw.net/img/2015/12/overfitting.jpg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://image.slidesharecdn.com/nncollovcapaldo2013-131220052427-phpapp01/95/machine-learning-introduction-to-neural-networks-12-638.jpg?cb=1393073301\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Another Example\n",
    "<img src=\"http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[1].png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name=\"introduction\"></a>\n",
    "## Introduction: Topic (5 mins)\n",
    "\n",
    "So far we've focused on fitting the **best model** to our data. In practice, we need\n",
    "to also make and **validate predictions** with our models. By **splitting our data** set\n",
    "into a **subset to train our model** on and a subset to make and test predictions\n",
    "on, we can **validate the effectiveness** of our model. This is called a **_train/test\n",
    "split_** and we'll explore a number of ways to effectively carry out the split.\n",
    "It's also a good way to avoid overfitting on your dataset (but not always).\n",
    "\n",
    "**Test/train split benefits:**\n",
    "* **Save a subset of data to make predictions**\n",
    "* **Can verify predictions without having to collect new data (which may be\n",
    "difficult or expensive)**\n",
    "* Can help avoid overfitting\n",
    "* Improve the quality of our predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## About Cross-Validation\n",
    "\n",
    "We use cross-validation to sample our data in order to understand how it may perform in a variety of cases, given a set of parameters.  It also helps us understand how predictions react to data.  Largely, we are \"testing\" how our model stands up to basic assumptions, given a model.\n",
    "\n",
    "Why Validate?\n",
    "\n",
    "- Test the model\n",
    "- Avoid overfitting\n",
    "- How well a model generalizes to an independet dataset\n",
    "\n",
    "_The goal of cross validation is to define a dataset to \"test\" the model in the training phase (i.e., the validation dataset), in order to limit problems like overfitting, give an insight on how the model will generalize to an independent dataset (i.e., an unknown dataset, for instance from a real problem), etc._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-Fold Validation\n",
    "\n",
    "Essentially, K-Fold splits our dataset up into K-Folds, and uses one segment to test.\n",
    "\n",
    "- Split data into K folds (subsets)\n",
    "- Use K-1 for training\n",
    "- Use 1 for testing\n",
    "- Repeat K times\n",
    "- Mean results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-Fold Validation In Action\n",
    "\n",
    "<img src=\"https://qph.is.quoracdn.net/main-qimg-c46f088d0ebf6598226e22aeac930512?convert_to_webp=true\" width=\"500\"a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick note about \"Hold Out\" validation\n",
    "\n",
    "Briefly, sometimes you'll hear about \"hold out\" validation.  Essentially, you ommit a section of data from any validation setup, in order to truly test unknown data against your model.\n",
    "\n",
    "The main reason you might try this:\n",
    "\n",
    "- Test your \"winning\" model against truly clean data\n",
    "- \"Truly clean\" is data a model has never seen \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTO NOTEBOOK!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## (2 mins) Question:  Is 2-fold cross-validation the same as a 50:50 test/train split?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "It may seem so at first glance, but with 2-fold cross-validation we get a\n",
    "prediction for every point since we use each half of the data to train and test\n",
    "separate models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## (2 mins) Question:  Will two different 50:50 (or x:y) splits produce the same model score?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Consider these cases:\n",
    "- Splits on time of day\n",
    "- Splits on categorical variables\n",
    "- Splits on dataframes with different bit masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In general no, and if the splits are chosen poorly along a categorical variable, the difference could be very large. For example, theme park attendence might be very different depending on the day of the week. Can students think\n",
    "of other examples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ADDITIONAL RESOURCES (SCIKIT)\n",
    "\n",
    "- [Cross-validation Example](http://scikit-learn.org/stable/auto_examples/exercises/plot_cv_diabetes.html#example-exercises-plot-cv-diabetes-py)\n",
    "- [Plotting Cross-Validated Predictions](http://scikit-learn.org/stable/auto_examples/plot_cv_predict.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "- Split data into testing and training sets\n",
    "- Perform cross validation scoring\n",
    "- Make cross validation predictions"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
