{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```---\n",
    "title: Gridsearch\n",
    "duration: \"1:25+\"\n",
    "creator:\n",
    "    name: David Yerrington\n",
    "    city: SF\n",
    "---```\n",
    "\n",
    "<img src=\"https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png\" style=\"float: left; margin: 15px;\">\n",
    "# GridSearch\n",
    "Week 3 | Lesson 4.3\n",
    "***\n",
    "\n",
    "\n",
    "![](https://snag.gy/aYcCt2.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion (5 mins)\n",
    "\n",
    "So far we have learned about linear regression and regularization.  _Given what you know about linear regression and how it's implemented in sklearn:_\n",
    "<br><br>\n",
    "## How would you approach tuning your model?\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap:  EDA, Analysis Strategy\n",
    "\n",
    "When doing exploratory analysis and starting to think about model selection, we have a few good starting points.\n",
    "\n",
    "- **Look at your data through subsetting and summary statistics**\n",
    "- Looking at coeficient matrices\n",
    "- Selecting features (variables) to use in our models\n",
    "- Considering parameters that might work, in a broad sense\n",
    "- Validation strategy\n",
    "\n",
    "A correlation matrix is used to investigate the **dependence between multiple variables at the same time**. The result is a table containing the correlation coefficients between each variable and the others. This is ideal for feature selection when deciding which features to use in a predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anyone use Gridsearch before?\n",
    "\n",
    "How / what / why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Gridsearch (10 mins)\n",
    "\n",
    "What is \"gridsearch\"? **Gridsearch** is the process of searching for the optimal set of tuning parameters for a model. **Gridsearch** is a scikit-learn method.  We use **Gridsearch** for searching across values of parameters, in combination with models, also using cross-validation to evaluate the effect to find the **best model**. It's called gridsearch because the idea is that there is a \"grid\" of parameters that are iteratively searched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Example\n",
    "\n",
    "So far we haven't really done much with tuning linear regression, other than regularization.  The prime example we will look at will be regularization, but let's first look at the mechanics of our model to establish some basic assumptions.\n",
    "\n",
    "### Linear Regression Parameters\n",
    "| Parameter | Potential Values |\n",
    "| --- | ---|\n",
    "| **fit_intercept** | bool: True/False |\n",
    "| **normalize** | bool:  True/False |\n",
    "\n",
    "> The normalize parameter:  If **True**, the regressors X will be normalized before  regression (they are talking about doing _standardization_ actually).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is as if we where to run, and score the following code, using all combinations of the specified parameters:\n",
    "\n",
    "```python\n",
    "\n",
    "# Case 1\n",
    "lm = LinearRegression(fit_itercept=True, normalize=False)\n",
    "model = lm.fit(X, y)\n",
    "score = model.score(X,y)\n",
    "\n",
    "# Case 2\n",
    "lm = LinearRegression(fit_itercept=False, normalize=False)\n",
    "model = lm.fit(X, y)\n",
    "score = model.score(X,y)\n",
    "\n",
    "# Case 3\n",
    "lm = LinearRegression(fit_itercept=True, normalize=True)\n",
    "model = lm.fit(X, y)\n",
    "score = model.score(X,y)\n",
    "\n",
    "# Case 4\n",
    "lm = LinearRegression(fit_itercept=False, normalize=False)\n",
    "model = lm.fit(X, y)\n",
    "score = model.score(X,y)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A More Sophisticated Example\n",
    "\n",
    "We haven't yet learned the intuition behind K-Nearest Neighbors, it's going to be introduced next week. So try to curb your curiousity for a moment about how this model works, and let's just talk about workflow and the programming mechanics for this example.\n",
    "\n",
    "Since **Gridsearch** is a method with a broad range of utility beyond regression problems, it's great for testing a combination of parameters on models that offer a broader range of **hyperparamters**.\n",
    "\n",
    "> Lingo guide:  **hyperparameter** is used interchangably with **parameter**, which is used with a given model. We are referring to the parameters we pass to our models to control their behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parameter | Potential Values |\n",
    "| --- | ---|\n",
    "| **n_neighbors** | int range 1-150 |\n",
    "| **weights** | strs:  \"uniform\", \"distance\" or user defined function |\n",
    "| **algorithm** | strs: \"ball_tree\", \"kd_tree\", \"brute\", \"auto\" |\n",
    "| **leaf_size** | int range 0-150 |\n",
    "| **metric** | str: \"minkowski\" or DistanceObject type |\n",
    "| **p** | int: 1=manhattan_distance, 2= euclidean_distance |\n",
    "\n",
    "### What is GridSearch doing?\n",
    "\n",
    "```python\n",
    "from sklearn import neighbors\n",
    "\n",
    "# Search - 1\n",
    "neighbors.KNeighborsClassifier(\n",
    "    n_neighbors   =  1, \n",
    "    weights       =  \"uniform\", \n",
    "    algorithm     =  \"ball_tree\", \n",
    "    leaf_size     =  30, \n",
    "    etc...\n",
    ")\n",
    "# Search - 2\n",
    "neighbors.KNeighborsClassifier(\n",
    "    n_neighbors   =  2, \n",
    "    weights       =  \"uniform\", \n",
    "    algorithm     =  \"ball_tree\", \n",
    "    leaf_size     =  30, \n",
    "    etc...\n",
    ")\n",
    "# Search - 3\n",
    "neighbors.KNeighborsClassifier(\n",
    "    n_neighbors   =  3, \n",
    "    weights       =  \"uniform\", \n",
    "    algorithm     =  \"ball_tree\", \n",
    "    leaf_size     =  30, \n",
    "    etc...\n",
    ")\n",
    "\n",
    "...\n",
    "... ** chunk chunk chunk -- [searching intensifies] -- hours later **\n",
    "...\n",
    "\n",
    "# Searching combinations of 300,000+\n",
    "neighbors.KNeighborsClassifier(\n",
    "    n_neighbors   =  150, \n",
    "    weights       =  \"distance\", \n",
    "    algorithm     =  \"auto\", \n",
    "    leaf_size     =  150, \n",
    "    etc...\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many models will be built and tested on a KNN model with the following parameters? (5 mins)\n",
    "\n",
    "- **n_neighbors**:  1-25\n",
    "- **algorithm**: \"ball_tree\", \"kd_tree\", \"brute\", \"auto\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Have Parameters\n",
    "\n",
    "Every model we will be learning have a predefined set of parameters.  If it has parameters, we can test a variety of parameters using gridsearch, to see the performance of various sets of parameters to get a sense of how they work in relation to our dataset and model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "## Do you remember which parameter CV was used for?\n",
    "<Br><Br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing GridsearchCV\n",
    "\n",
    "By default the `cv` parameter is `3`.  You can set this as high as you want!  Keep in mind how it works and why it's used.  If this is a mystery, please review our material on K-Folds validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load gridsearch, libraries, test data\n",
    "from sklearn import grid_search, datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd, patsy\n",
    "\n",
    "columns =  \"age sex bmi map tc ldl hdl tch ltg glu\".split()\n",
    "\n",
    "data    =  datasets.load_diabetes()\n",
    "df      =  pd.DataFrame(data.data, columns=columns)\n",
    "df['target'] = data.target\n",
    "\n",
    "# Setup patsy design matrix\n",
    "y, X    =  patsy.dmatrices(\"target ~ age + sex + bmi + map + tc + ldl + glu\", data=df, return_type=\"dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup GridSearchCV Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup our GridSearch Parmaters\n",
    "search_parameters = {\n",
    "    'fit_intercept':  [True, False], \n",
    "    'normalize':      [False, True]\n",
    "}\n",
    "\n",
    "# Intialize a blank model object\n",
    "lm = LinearRegression()\n",
    "\n",
    "# Initialize gridsearch\n",
    "estimator = grid_search.GridSearchCV(lm, search_parameters, cv=5)\n",
    "\n",
    "# Fit some data!\n",
    "results = estimator.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Results\n",
    "\n",
    "There are a number of interesting result properties to explore.\n",
    "\n",
    "| Property | Use |\n",
    "| --- | ---|\n",
    "| **`results.param_grid`** | Displays parameters used |\n",
    "| **`results.best_score_`** | Best score achieved |\n",
    "| **`results.best_estimator_`** | Reference to model with best score.  Is usable / callable. |\n",
    "| **`results.best_params_`** | The parameters that have been found to perform with the best score. |\n",
    "| **`results.grid_scores_`** | Display score attributes with cooresponding parameters | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:\n",
      "0.370689510527\n",
      "\n",
      "Best Params:\n",
      "{'normalize': False, 'fit_intercept': False}\n"
     ]
    }
   ],
   "source": [
    "print \"Best Score:\"\n",
    "print results.best_score_\n",
    "\n",
    "print\n",
    "\n",
    "print \"Best Params:\"\n",
    "print results.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find All Tested Params with Scores\n",
    "_In the case of linear regression, the R2 isn't displayed, which is annoying.  You should at least know how where to look for the future use cases when you use other models_.\n",
    "\n",
    "It's not applicable now, but this is a great place to get data to plot your parameter values and their impact on your score as they change.  We will explore this possibility in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.37069, std: 0.07662, params: {'normalize': False, 'fit_intercept': True},\n",
       " mean: 0.37069, std: 0.07662, params: {'normalize': True, 'fit_intercept': True},\n",
       " mean: 0.37069, std: 0.07662, params: {'normalize': False, 'fit_intercept': False},\n",
       " mean: 0.37069, std: 0.07662, params: {'normalize': True, 'fit_intercept': False}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "## (5 mins) How do you think we can use gridsearch to avoid overfitting?\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (20 mins)  Idependent Practice\n",
    "\n",
    "Setup a basic gridsearch with all potential parameters for **fit_intercept**, and **normalize** parameters for linear regression using the boston housing dataset.\n",
    "\n",
    "1. Select a set of predictors\n",
    "1. Use the provided target as your response\n",
    "1. Setup and perform a basic gridsearch on a blank linear model object\n",
    "1. Print our your results\n",
    "\n",
    "> _The actual results won't be that interesting but the important thing is that you understand the implementation._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'feature_names', 'DESCR', 'target']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_boston()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><Br>\n",
    "\n",
    "# (5 mins)  What are some disadvantages to GridSearch that you can think of?\n",
    "\n",
    "<br><Br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Check-in\n",
    "\n",
    "- What is the most difficult thing to understand about GridSearch?\n",
    "- How many parameters can be searched?\n",
    "- How do we know if our best score is good or not?\n",
    "- Which models can we use with Gridsearch?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (60 mins) Independent/Group Practice\n",
    "\n",
    "Feel free to partner up or work within your group.  Use gridsearch to setup a basic pipeline on to search for `alpha` parameters for Lasso regularized regression.\n",
    "\n",
    "1.  Load up the winedataset used from our regularization lab yesterday.\n",
    "1.  Import Lasso, patsy\n",
    "1.  Use patsy to setup a design matrix\n",
    "1.  Setup a range of alphas to test _(hint: numpy generator)_\n",
    "1.  Setup gridsearch parameters with your range of alphas\n",
    "1.  Initialize and gridsearch\n",
    "1.  Review / print performance metrics and decide on an optimal parameter for alpha\n",
    "\n",
    "Remember:  _Alphas for the Lasso tend to effect regularization linearly rather than by orders of magnitude like in the ridge. A linear series of alphas is sufficient. Don't worry about the warning for Lasso at alpha 0._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Don't feel like you need to tackle these in any particular order!  The coef / plotting challenge is actually pretty tricky._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge #1\n",
    "Figure out how to plot the impact of your score given the range of parameters used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge #2\n",
    "\n",
    "Investigate the effect of coefficients given the range of alphas used, in addition to scores.  You might try to plot a few of these within a range of parameters used.  How can you evaluate this?  There is more than one way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge #3\n",
    "\n",
    "Attempt the same exercize using ridge and/or elasticnet, adjusting parameters for appropriate range/scale.  Also, attempt scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
