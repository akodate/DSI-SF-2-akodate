{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision-recall vs. ROC lab\n",
    "\n",
    "In this lab you'll explore the differences between the ROC and PRAUC plot, as well as what changes when you optimize a gridsearch for different metrics - in this case changing the optimization from accuracy to \"f1-score\".\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import patsy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Load a classification dataset\n",
    "\n",
    "The data you can use is up to you for this lab, but I've put two new datasets here if you want to try them out (they are used in the solutions.)\n",
    "\n",
    "The first is a dataset on police killings. This dataset is pretty small and the model's don't fit that well from the ones I tried out, but your code will be fast.\n",
    "\n",
    "The second is a cleaned up dataset on a stack overflow survey given out this year. I have only recently cleaned this one and so haven't tried out many models. I think this would be the more interesting one but it has more rows so your code may take longer, depending on your model specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pk = pd.read_csv('/Users/kiefer/github-repos/DSI-SF-2/datasets/police_killings/police-killings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sos = pd.read_csv('/Users/kiefer/github-repos/DSI-SF-2/datasets/stack_overflow_surveys/survey_simple_cleaned_nonull.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Clean and/or explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Create two or three binary target variables to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Using patsy (or manually) create corresponding predictor matrices for your target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Break up your predictors and targets with train_test_split\n",
    "\n",
    "**Use the `stratify` option! It takes as its argument the target variable vector.**\n",
    "\n",
    "Choose a reasonable test size that's not too small. 0.3 to 0.4 is probably good, but depends on your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Gridsearch best parameters for your models\n",
    "\n",
    "For each of your target variables, optimize parameters with gridsearch **fitting on the training data from above**. We will be saving the test data for later.\n",
    "\n",
    "It is up to you whether you want to fit a LogisticRegression or KNeighborsClassifier (or both?).\n",
    "\n",
    "Example parameters to search for with LogisticRegression:\n",
    "\n",
    "    {'solver':['liblinear'], 'penalty':['l1','l2'], 'C':np.linspace(0.0001, 1000., 100)}\n",
    "    \n",
    "Example parameters to search for with KNeighborsClassifier:\n",
    "\n",
    "    {'n_neighbors':range(1,100), 'weights':['uniform','distance']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Compare performance of your models against baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Create a function to plot an ROC curve\n",
    "\n",
    "Your function will probably take a model, and X matrix and y target vector. This way you can use `roc_curve` and `auc` to get the stuff needed for the plot.\n",
    "\n",
    "See the sklearn example here:\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Plot ROC curves using your models and the test data you split off earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Calculate confusion matrices for your models on the training and testing data\n",
    "\n",
    "What do they tell you about the models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Write a function to plot the precision-recall curve\n",
    "\n",
    "It's very similar code to the ROC curve. \n",
    "\n",
    "See here for an example:\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import (precision_recall_curve, average_precision_score, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Plot precision-recall curves using your models on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Run new gridsearches with keyword argument `scoring='f1'` for your data\n",
    "\n",
    "The f1-score is a metric combining performance on both precision and recall. It is similar to area under the precision recall curve.  \n",
    "\n",
    "Setting the scoring to this will now have the gridsearch optimize the parameters to find the best f1-score as opposed to the best accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Calculate the confusion matrices using the new models on the train or test data.\n",
    "\n",
    "Has anything changed? Why would that be the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
