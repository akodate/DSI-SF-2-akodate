{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis and naive bayes\n",
    "\n",
    "Now that you've seen sentiment analysis using a predefined dictionary of positive and negative valence for different words, this lab will have you do sentiment analysis on the movie review dataset \"in reverse\": you'll find which words are most likely to appear in positive or negative valenced reviews.\n",
    "\n",
    "---\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "For this lab we're going to use a classifier common in NLP and sentiment analysis called Naive Bayes. We'll be covering Naive Bayes classifiers in more depth in a later lecture â€“ for this lab you'll just be implementing it using sklearn.\n",
    "\n",
    "Essentially, Naive Bayes solves an inverted problem to what you are used to in supervized learning. Given a feature $x_i$ and target $y$, it solves for $P(x_i | y)$. In other words, the probability of a feature/predictor _given_ that the target is 1.\n",
    "\n",
    "We'll use this to figure out which words are more likely to appear when the target is 1 (\"fresh\") vs when the target is 0 (\"rotten\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Load packages and movie data\n",
    "\n",
    "Do any cleaning you deem necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# We are using the BernoulliNB version of Naive Bayes, which assumes predictors are binary encoded.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt = pd.read_csv('/Users/kiefer/github-repos/DSI-SF-2/datasets/rottentomatoes_critics/rt_critics.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Create a predictor matrix of words from the quotes with CountVectorizer\n",
    "\n",
    "It is up to you what ngram range you want to select. **Make sure that `binary=True`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Split data into training and testing splits\n",
    "\n",
    "You should keep 25% of the data in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Build a `BernoulliNB` model predicting fresh vs. rotten from the word appearances\n",
    "\n",
    "The model should only be built (and cross-validated) on the training data.\n",
    "\n",
    "Cross-validate the score and compare it to baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Pull out the probability of words given \"fresh\"\n",
    "\n",
    "The `.feature_log_prob_` attribute of the naive bayes model contains the log probabilities of a feature appearing given a target class.\n",
    "\n",
    "The rows correspond to the class of the target, and the columns correpsond to the features. The first row is the 0 \"rotten\" class, and the second is the 1 \"fresh\" class.\n",
    "\n",
    "#### 1. Pull out the log probabilities and convert them to probabilities (for fresh and for rotten)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Make a dataframe with the probabilities and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create a column that is the difference between fresh probability of appearance and rotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Look at the most likely words for fresh and rotten reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Examine how your model performs on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Look at the top 10 movies and reviews likely to be fresh and top 10 likely to be rotten\n",
    "\n",
    "You can fit the model on the full set of data for this.\n",
    "\n",
    "Just to note: Naive Bayes, while good at classifying, is known to be somewhat bad at giving accurate predicted probabilities (beyond getting it on the correct side of 50%). It is a good classifier but a bad estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## [Bonus] Find out which critics are likely to give the \"freshest\" and \"rottenest\" reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
