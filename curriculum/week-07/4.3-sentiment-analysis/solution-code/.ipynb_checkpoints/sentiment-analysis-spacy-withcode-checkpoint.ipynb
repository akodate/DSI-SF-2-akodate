{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis codealong using spacy and movie reviews\n",
    "\n",
    "Sentiment analysis is one of the more popular topics in NLP. It is concerned with finding some kind of valence to written text. This could be positivity, negativity, subjectivity and many others. In this lesson we will just be looking at those three. \n",
    "\n",
    "First we will load in a dataset of pre-coded sentiment scores for positivity and negativity on words. These words are also divided up by their part of speech in the sentence.\n",
    "\n",
    "Then we will load snippets of rottentomatoes reviews and explore the sentiment of the writing.\n",
    "\n",
    "---\n",
    "\n",
    "### Load packages and sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sen = pd.read_csv('/Users/kiefer/github-repos/DSI-SF-2/datasets/sentiment_words/sentiment_words_simple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adj</td>\n",
       "      <td>.22-caliber</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adj</td>\n",
       "      <td>.22-calibre</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adj</td>\n",
       "      <td>.22_caliber</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adj</td>\n",
       "      <td>.22_calibre</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj</td>\n",
       "      <td>.38-caliber</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pos         word  pos_score  neg_score\n",
       "0  adj  .22-caliber        0.0        0.0\n",
       "1  adj  .22-calibre        0.0        0.0\n",
       "2  adj  .22_caliber        0.0        0.0\n",
       "3  adj  .22_calibre        0.0        0.0\n",
       "4  adj  .38-caliber        0.0        0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sen.pos = sen.pos.map(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Create a sentiment dataset that does not take into account part of speech tags\n",
    "\n",
    "This will be what we use first, not knowing the part of speech a word is in. Later when we use spacy we will be able to determine the part of speech of each word and pair the scores accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sen_agg = sen[['word','pos_score','neg_score']].groupby('word').agg(np.mean).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'hood</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'s_gravenhage</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'tween</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'tween_decks</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.22</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  pos_score  neg_score\n",
       "0          'hood      0.000      0.375\n",
       "1  's_gravenhage      0.000      0.000\n",
       "2         'tween      0.000      0.000\n",
       "3   'tween_decks      0.000      0.000\n",
       "4            .22      0.125      0.000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Create a dictionary version of the sentiment data for both the part of speech and aggregate\n",
    "\n",
    "The dictionary format of the data will be much easier to index into in our functions later. If we don't do this it's much harder to make those functions run quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n"
     ]
    }
   ],
   "source": [
    "sen_dict = {'ADJ':{},'NOUN':{},'VERB':{},'ADV':{}}\n",
    "\n",
    "for i, row in enumerate(sen.itertuples()):\n",
    "    if (i % 10000) == 0:\n",
    "        print i\n",
    "    sen_dict[row[1]][row[2]] = {'pos_score':row[3], 'neg_score':row[4]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n"
     ]
    }
   ],
   "source": [
    "sen_agg_dict = {}\n",
    "for i, row in enumerate(sen_agg.itertuples()):\n",
    "    if (i % 10000) == 0:\n",
    "        print i\n",
    "    sen_agg_dict[row[1]] = {'pos_score':row[2], 'neg_score':row[3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Load the rotten tomatoes dataset\n",
    "\n",
    "This dataset has:\n",
    "    \n",
    "    critic: critic's name\n",
    "    fresh: fresh vs. rotten rating\n",
    "    imdb: code for imdb\n",
    "    publication: where the review was published\n",
    "    quote: the review snippet\n",
    "    review_date: date of review\n",
    "    rtid: rottentomatoes id\n",
    "    title: name of movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt = pd.read_csv('/Users/kiefer/github-repos/DSI-SF-2/datasets/rottentomatoes_critics/rt_critics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh      imdb     publication  \\\n",
       "0         Derek Adams  fresh  114709.0        Time Out   \n",
       "1     Richard Corliss  fresh  114709.0   TIME Magazine   \n",
       "2         David Ansen  fresh  114709.0        Newsweek   \n",
       "3       Leonard Klady  fresh  114709.0         Variety   \n",
       "4  Jonathan Rosenbaum  fresh  114709.0  Chicago Reader   \n",
       "\n",
       "                                               quote review_date    rtid  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04  9559.0   \n",
       "1                  The year's most inventive comedy.  2008-08-31  9559.0   \n",
       "2  A winning animated feature that has something ...  2008-08-18  9559.0   \n",
       "3  The film sports a provocative and appealing st...  2008-06-09  9559.0   \n",
       "4  An entertaining computer-generated, hyperreali...  2008-03-10  9559.0   \n",
       "\n",
       "       title  \n",
       "0  Toy story  \n",
       "1  Toy story  \n",
       "2  Toy story  \n",
       "3  Toy story  \n",
       "4  Toy story  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Restrict data to reviews with valid ratings and reviews over 10 words long\n",
    "\n",
    "Clean up the reviews, making a column with the case and punctuation removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt = rt[rt.fresh.isin(['fresh','rotten'])]\n",
    "rt.fresh = rt.fresh.map(lambda x: 1 if x == 'fresh' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11215, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt['quote_len'] = rt.quote.map(lambda x: len(x.split()))\n",
    "rt = rt[rt.quote_len > 10]\n",
    "rt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "rt['qt'] = rt.quote.map(lambda x: unicode(''.join([y for y in list(x.lower()) if y in string.ascii_lowercase+\" -'\"])))\n",
    "rt.qt = rt.qt.map(lambda x: x.replace('-',' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Write a function to assign positive rating, negative, and objective based on words in review\n",
    "\n",
    "We'll use the dictionary we constructed above (without the part of speech tags). \n",
    "\n",
    "Objectivity is calculated: \n",
    "\n",
    "    1. - (positive_score + negative_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def agg_scorer(x):\n",
    "    x = x.split()\n",
    "    pos_scores, neg_scores, obj_scores = [], [], []\n",
    "    for token in x:\n",
    "        try:\n",
    "            pos_scores.append(sen_agg_dict[token]['pos_score'])\n",
    "            neg_scores.append(sen_agg_dict[token]['neg_score'])\n",
    "            obj_scores.append((1. - (pos_scores[-1] + neg_scores[-1])))\n",
    "        except:\n",
    "            pos_scores.append(0.)\n",
    "            neg_scores.append(0.)\n",
    "            obj_scores.append(1.)\n",
    "    return [pos_scores, neg_scores, obj_scores]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agg_scores = map(agg_scorer, rt.qt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Calculate the sum and average ratings for positive, negative, and objective for each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt['pos_avg'] = [np.mean(x[0]) for x in agg_scores]\n",
    "rt['neg_avg'] = [np.mean(x[1]) for x in agg_scores]\n",
    "rt['obj_avg'] = [np.mean(x[2]) for x in agg_scores]\n",
    "\n",
    "rt['pos_sum'] = [np.sum(x[0]) for x in agg_scores]\n",
    "rt['neg_sum'] = [np.sum(x[1]) for x in agg_scores]\n",
    "rt['obj_sum'] = [np.sum(x[2]) for x in agg_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "      <th>quote_len</th>\n",
       "      <th>qt</th>\n",
       "      <th>pos_avg</th>\n",
       "      <th>neg_avg</th>\n",
       "      <th>obj_avg</th>\n",
       "      <th>pos_sum</th>\n",
       "      <th>neg_sum</th>\n",
       "      <th>obj_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>24</td>\n",
       "      <td>so ingenious in concept design and execution t...</td>\n",
       "      <td>0.046599</td>\n",
       "      <td>0.027885</td>\n",
       "      <td>0.925517</td>\n",
       "      <td>1.164969</td>\n",
       "      <td>0.697115</td>\n",
       "      <td>23.137916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>13</td>\n",
       "      <td>a winning animated feature that has something ...</td>\n",
       "      <td>0.062271</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.915751</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>11.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>17</td>\n",
       "      <td>the film sports a provocative and appealing st...</td>\n",
       "      <td>0.057831</td>\n",
       "      <td>0.024271</td>\n",
       "      <td>0.917897</td>\n",
       "      <td>0.983135</td>\n",
       "      <td>0.412608</td>\n",
       "      <td>15.604257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>14</td>\n",
       "      <td>an entertaining computer generated hyperrealis...</td>\n",
       "      <td>0.067496</td>\n",
       "      <td>0.039307</td>\n",
       "      <td>0.893197</td>\n",
       "      <td>0.944940</td>\n",
       "      <td>0.550298</td>\n",
       "      <td>12.504762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Michael Booth</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Denver Post</td>\n",
       "      <td>As Lion King did before it, Toy Story revived ...</td>\n",
       "      <td>2007-05-03</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>40</td>\n",
       "      <td>as lion king did before it toy story revived t...</td>\n",
       "      <td>0.028408</td>\n",
       "      <td>0.021935</td>\n",
       "      <td>0.949657</td>\n",
       "      <td>1.136316</td>\n",
       "      <td>0.877397</td>\n",
       "      <td>37.986287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh      imdb     publication  \\\n",
       "0         Derek Adams      1  114709.0        Time Out   \n",
       "2         David Ansen      1  114709.0        Newsweek   \n",
       "3       Leonard Klady      1  114709.0         Variety   \n",
       "4  Jonathan Rosenbaum      1  114709.0  Chicago Reader   \n",
       "5       Michael Booth      1  114709.0     Denver Post   \n",
       "\n",
       "                                               quote review_date    rtid  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04  9559.0   \n",
       "2  A winning animated feature that has something ...  2008-08-18  9559.0   \n",
       "3  The film sports a provocative and appealing st...  2008-06-09  9559.0   \n",
       "4  An entertaining computer-generated, hyperreali...  2008-03-10  9559.0   \n",
       "5  As Lion King did before it, Toy Story revived ...  2007-05-03  9559.0   \n",
       "\n",
       "       title  quote_len                                                 qt  \\\n",
       "0  Toy story         24  so ingenious in concept design and execution t...   \n",
       "2  Toy story         13  a winning animated feature that has something ...   \n",
       "3  Toy story         17  the film sports a provocative and appealing st...   \n",
       "4  Toy story         14  an entertaining computer generated hyperrealis...   \n",
       "5  Toy story         40  as lion king did before it toy story revived t...   \n",
       "\n",
       "    pos_avg   neg_avg   obj_avg   pos_sum   neg_sum    obj_sum  \n",
       "0  0.046599  0.027885  0.925517  1.164969  0.697115  23.137916  \n",
       "2  0.062271  0.021978  0.915751  0.809524  0.285714  11.904762  \n",
       "3  0.057831  0.024271  0.917897  0.983135  0.412608  15.604257  \n",
       "4  0.067496  0.039307  0.893197  0.944940  0.550298  12.504762  \n",
       "5  0.028408  0.021935  0.949657  1.136316  0.877397  37.986287  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Evaluate predictive ability using the sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.624431210669 0.615069103879\n"
     ]
    }
   ],
   "source": [
    "X = rt[['pos_avg','neg_avg','obj_avg','quote_len']]\n",
    "y = rt.fresh.values\n",
    "\n",
    "lr_scores = cross_val_score(LogisticRegression(), X, y, cv=10)\n",
    "print np.mean(lr_scores), rt.fresh.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Import spacy\n",
    "\n",
    "The spacy package is the current gold standard for parsing text. We are going to use it to find the part of speech tags for the review words. \n",
    "\n",
    "Once we have parsed the tags with spacey, we can assign sentiment scores at a more granular level, using the correct part of speech version of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "en_nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = en_nlp(rt.qt.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "so ingenious in concept design and execution that you could watch it on a postage stamp sized screen and still be engulfed by its charm"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "concept"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADV\n",
      "ADJ\n",
      "ADP\n",
      "NOUN\n",
      "NOUN\n",
      "CONJ\n",
      "NOUN\n",
      "ADJ\n",
      "PRON\n",
      "VERB\n",
      "VERB\n",
      "PRON\n",
      "ADP\n",
      "DET\n",
      "NOUN\n",
      "NOUN\n",
      "VERB\n",
      "NOUN\n",
      "CONJ\n",
      "ADV\n",
      "VERB\n",
      "VERB\n",
      "ADP\n",
      "ADJ\n",
      "NOUN\n"
     ]
    }
   ],
   "source": [
    "for token in tmp:\n",
    "    print token.pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ADV' == tmp[0].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0].pos_ in ['ADV','NOUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tok = tmp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11215, 16)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Parse the quotes using spacey's multithreaded parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n"
     ]
    }
   ],
   "source": [
    "parsed_quotes = []\n",
    "for i, parsed in enumerate(en_nlp.pipe(rt.qt.values, batch_size=50, n_threads=4)):\n",
    "    assert parsed.is_parsed\n",
    "    if (i % 1000) == 0:\n",
    "        print i\n",
    "    parsed_quotes.append(parsed)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Create columns for part of speech proportions\n",
    "\n",
    "For each of the part of speech tags, create a column in the dataset that records the proportion of words in the quote that have that part of speech tag. We can try using these as predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'ADJ' u'ADP' u'ADV' u'CONJ' u'DET' u'INTJ' u'NOUN' u'NUM' u'PART' u'PRON'\n",
      " u'PROPN' u'PUNCT' u'SPACE' u'SYM' u'VERB' u'X']\n"
     ]
    }
   ],
   "source": [
    "unique_pos = []\n",
    "for parsed in parsed_quotes:\n",
    "    unique_pos.extend([t.pos_ for t in parsed])\n",
    "unique_pos = np.unique(unique_pos)\n",
    "print unique_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pos in unique_pos:\n",
    "    rt[pos+'_prop'] = 0.\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n"
     ]
    }
   ],
   "source": [
    "rt = rt.reset_index(drop=True)\n",
    "for i, parsed in enumerate(parsed_quotes):\n",
    "    if (i % 1000) == 0:\n",
    "        print i\n",
    "    parsed_len = len(parsed)\n",
    "    for pos in unique_pos:\n",
    "        count = len([x for x in parsed if x.pos_ == pos])\n",
    "        rt.ix[i, pos+'_prop'] = float(count)/parsed_len\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "      <th>quote_len</th>\n",
       "      <th>qt</th>\n",
       "      <th>...</th>\n",
       "      <th>NOUN_prop</th>\n",
       "      <th>NUM_prop</th>\n",
       "      <th>PART_prop</th>\n",
       "      <th>PRON_prop</th>\n",
       "      <th>PROPN_prop</th>\n",
       "      <th>PUNCT_prop</th>\n",
       "      <th>SPACE_prop</th>\n",
       "      <th>SYM_prop</th>\n",
       "      <th>VERB_prop</th>\n",
       "      <th>X_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>24</td>\n",
       "      <td>so ingenious in concept design and execution t...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>13</td>\n",
       "      <td>a winning animated feature that has something ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>17</td>\n",
       "      <td>the film sports a provocative and appealing st...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>14</td>\n",
       "      <td>an entertaining computer generated hyperrealis...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael Booth</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Denver Post</td>\n",
       "      <td>As Lion King did before it, Toy Story revived ...</td>\n",
       "      <td>2007-05-03</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>40</td>\n",
       "      <td>as lion king did before it toy story revived t...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh      imdb     publication  \\\n",
       "0         Derek Adams      1  114709.0        Time Out   \n",
       "1         David Ansen      1  114709.0        Newsweek   \n",
       "2       Leonard Klady      1  114709.0         Variety   \n",
       "3  Jonathan Rosenbaum      1  114709.0  Chicago Reader   \n",
       "4       Michael Booth      1  114709.0     Denver Post   \n",
       "\n",
       "                                               quote review_date    rtid  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04  9559.0   \n",
       "1  A winning animated feature that has something ...  2008-08-18  9559.0   \n",
       "2  The film sports a provocative and appealing st...  2008-06-09  9559.0   \n",
       "3  An entertaining computer-generated, hyperreali...  2008-03-10  9559.0   \n",
       "4  As Lion King did before it, Toy Story revived ...  2007-05-03  9559.0   \n",
       "\n",
       "       title  quote_len                                                 qt  \\\n",
       "0  Toy story         24  so ingenious in concept design and execution t...   \n",
       "1  Toy story         13  a winning animated feature that has something ...   \n",
       "2  Toy story         17  the film sports a provocative and appealing st...   \n",
       "3  Toy story         14  an entertaining computer generated hyperrealis...   \n",
       "4  Toy story         40  as lion king did before it toy story revived t...   \n",
       "\n",
       "    ...    NOUN_prop  NUM_prop  PART_prop  PRON_prop  PROPN_prop  PUNCT_prop  \\\n",
       "0   ...     0.280000       0.0   0.000000   0.080000         0.0         0.0   \n",
       "1   ...     0.384615       0.0   0.000000   0.000000         0.0         0.0   \n",
       "2   ...     0.277778       0.0   0.000000   0.000000         0.0         0.0   \n",
       "3   ...     0.437500       0.0   0.000000   0.000000         0.0         0.0   \n",
       "4   ...     0.325581       0.0   0.023256   0.046512         0.0         0.0   \n",
       "\n",
       "   SPACE_prop  SYM_prop  VERB_prop  X_prop  \n",
       "0      0.0000       0.0   0.200000     0.0  \n",
       "1      0.0000       0.0   0.153846     0.0  \n",
       "2      0.0000       0.0   0.055556     0.0  \n",
       "3      0.0625       0.0   0.187500     0.0  \n",
       "4      0.0000       0.0   0.139535     0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Evaluate a model with the new part of speech predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.637539340142 0.615069103879\n"
     ]
    }
   ],
   "source": [
    "X = rt[['pos_avg','neg_avg','obj_avg','quote_len']+[x for x in rt.columns if x.endswith('_prop')]]\n",
    "y = rt.fresh.values\n",
    "\n",
    "lr_scores = cross_val_score(LogisticRegression(), X, y, cv=10)\n",
    "print np.mean(lr_scores), rt.fresh.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([   u'pos_avg',    u'neg_avg',    u'obj_avg',  u'quote_len',\n",
       "         u'ADJ_prop',   u'ADP_prop',   u'ADV_prop',  u'CONJ_prop',\n",
       "         u'DET_prop',  u'INTJ_prop',  u'NOUN_prop',   u'NUM_prop',\n",
       "        u'PART_prop',  u'PRON_prop', u'PROPN_prop', u'PUNCT_prop',\n",
       "       u'SPACE_prop',   u'SYM_prop',  u'VERB_prop',     u'X_prop'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_avg 8.76697959874\n",
      "neg_avg -7.33385858761\n",
      "obj_avg -0.634641104609\n",
      "quote_len 0.0116093439938\n",
      "ADJ_prop 0.961052406301\n",
      "ADP_prop 0.0732935970155\n",
      "ADV_prop -2.05180196625\n",
      "CONJ_prop 1.60400681916\n",
      "DET_prop -0.723469079008\n",
      "INTJ_prop -0.105599029459\n",
      "NOUN_prop 0.905379519771\n",
      "NUM_prop 1.02922089112\n",
      "PART_prop -1.52186110803\n",
      "PRON_prop 1.55185184176\n",
      "PROPN_prop 1.80559660429\n",
      "PUNCT_prop -0.468802105115\n",
      "SPACE_prop -0.167968297252\n",
      "SYM_prop 0.0290852861332\n",
      "VERB_prop -2.26374980084\n",
      "X_prop 0.14224432693\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression().fit(X, y)\n",
    "for var, coef in zip(X.columns, lr.coef_[0]):\n",
    "    print var, coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Print out the most likely fresh and most likely rotten reviews\n",
    "\n",
    "Using the predicted probabilities from our model, we can see which reviews are most likely to be fresh or rotten. We can easily validate that our model is doing something that makes sense by looking at these (one of the benefits of doing NLP work!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = pd.DataFrame(lr.predict_proba(X), columns=['rotten_prob','fresh_prob'])\n",
    "pp['ind'] = range(pp.shape[0])\n",
    "pp['quote'] = rt.quote.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_prob</th>\n",
       "      <th>fresh_prob</th>\n",
       "      <th>ind</th>\n",
       "      <th>quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.336702</td>\n",
       "      <td>0.663298</td>\n",
       "      <td>0</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.309864</td>\n",
       "      <td>0.690136</td>\n",
       "      <td>1</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.263624</td>\n",
       "      <td>0.736376</td>\n",
       "      <td>2</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.401442</td>\n",
       "      <td>0.598558</td>\n",
       "      <td>3</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.280006</td>\n",
       "      <td>0.719994</td>\n",
       "      <td>4</td>\n",
       "      <td>As Lion King did before it, Toy Story revived ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rotten_prob  fresh_prob  ind  \\\n",
       "0     0.336702    0.663298    0   \n",
       "1     0.309864    0.690136    1   \n",
       "2     0.263624    0.736376    2   \n",
       "3     0.401442    0.598558    3   \n",
       "4     0.280006    0.719994    4   \n",
       "\n",
       "                                               quote  \n",
       "0  So ingenious in concept, design and execution ...  \n",
       "1  A winning animated feature that has something ...  \n",
       "2  The film sports a provocative and appealing st...  \n",
       "3  An entertaining computer-generated, hyperreali...  \n",
       "4  As Lion King did before it, Toy Story revived ...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp.sort_values('fresh_prob', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An ingenious script, excellent special effects and photography, and superior acting, make it an endearing winner.\n",
      "============================================================\n",
      "\n",
      "The Karate Kid exhibits warmth and friendly, predictable humor, its greatest assets.\n",
      "============================================================\n",
      "\n",
      "Like chamber music, Metropolitan is sprightly, intimate and all too self-aware.\n",
      "============================================================\n",
      "\n",
      "Appropriately operatic, Chen's visually spectacular epic is sumptuous in every respect. Intelligent, enthralling, rhapsodic.\n",
      "============================================================\n",
      "\n",
      "From Russia with Love is a preposterous, skillful slab of hardhitting, sexy hokum.\n",
      "============================================================\n",
      "\n",
      "An unashamed study of selfish, sadistic criminality, and all the better for it.\n",
      "============================================================\n",
      "\n",
      "A very good film with some dazzling moments and one truly outstanding performance!\n",
      "============================================================\n",
      "\n",
      "Some nifty celestial surfing and a good finale compensate for a dead midsection.\n",
      "============================================================\n",
      "\n",
      "The Whole Nine Yards a bright crowd-pleaser with a clever script.\n",
      "============================================================\n",
      "\n",
      "A flawed but powerful Shine-esque tale of love, music, and madness!\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for quote in pp.quote[0:10]:\n",
    "    print quote\n",
    "    print '============================================================\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp.sort_values('rotten_prob', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bringing Out the Dead is stunning to look at; unfortunately, it's not terribly satisfying to watch.\n",
      "============================================================\n",
      "\n",
      "Don't bother to hang around for the outtakes. They're not funny either.\n",
      "============================================================\n",
      "\n",
      "If inspiration is lacking, talent is not. Count Lynch down but never out.\n",
      "============================================================\n",
      "\n",
      "Unfortunately, and perhaps not unexpectedly, it doesn't live up to the hype.\n",
      "============================================================\n",
      "\n",
      "I've rarely laughed so much at a movie I generally disliked.\n",
      "============================================================\n",
      "\n",
      "Not only about PCs; it appears to have been dictated by one.\n",
      "============================================================\n",
      "\n",
      "Things might be bad, the movie suggests, but they're not so bad you can't laugh.\n",
      "============================================================\n",
      "\n",
      "You can never expect to see a film more handsomely played.\n",
      "============================================================\n",
      "\n",
      "It would be difficult to imagine material more wrong for Spade than Lost & Found.\n",
      "============================================================\n",
      "\n",
      "Not even Eddie can save this ill-conceived mess of a movie.\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for quote in pp.quote[0:10]:\n",
    "    print quote\n",
    "    print '============================================================\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Assign sentiment scores using the correct part of speech tag\n",
    "\n",
    "We need to write another function that will take into account the part of speech tags using the parsed quotes we created earlier and the original sentiment data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scorer(parsed):\n",
    "    pos_scores, neg_scores, obj_scores = [], [], []\n",
    "    for token in [t for t in parsed if t.pos_ in ['NOUN','VERB','ADV','ADJ']]:\n",
    "        try:\n",
    "            pos_scores.append(sen_dict[token.pos_][str(token)]['pos_score'])\n",
    "            neg_scores.append(sen_dict[token.pos_][str(token)]['neg_score'])\n",
    "            obj_scores.append((1. - (pos_scores[-1] + neg_scores[-1])))\n",
    "        except:\n",
    "            pos_scores.append(0.)\n",
    "            neg_scores.append(0.)\n",
    "            obj_scores.append(1.)\n",
    "    return [pos_scores, neg_scores, obj_scores]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i, parsed in enumerate(parsed_quotes):\n",
    "    if (i % 1000) == 0:\n",
    "        print i\n",
    "    scores.append(scorer(parsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rt['pos_part_avg'] = [np.mean(x[0]) for x in scores]\n",
    "rt['neg_part_avg'] = [np.mean(x[1]) for x in scores]\n",
    "rt['obj_part_avg'] = [np.mean(x[2]) for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt['pos_part_sum'] = [np.sum(x[0]) for x in scores]\n",
    "rt['neg_part_sum'] = [np.sum(x[1]) for x in scores]\n",
    "rt['obj_part_sum'] = [np.sum(x[2]) for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "      <th>quote_len</th>\n",
       "      <th>qt</th>\n",
       "      <th>...</th>\n",
       "      <th>SPACE_prop</th>\n",
       "      <th>SYM_prop</th>\n",
       "      <th>VERB_prop</th>\n",
       "      <th>X_prop</th>\n",
       "      <th>pos_part_avg</th>\n",
       "      <th>neg_part_avg</th>\n",
       "      <th>obj_part_avg</th>\n",
       "      <th>pos_part_sum</th>\n",
       "      <th>neg_part_sum</th>\n",
       "      <th>obj_part_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>24</td>\n",
       "      <td>so ingenious in concept design and execution t...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065510</td>\n",
       "      <td>0.021877</td>\n",
       "      <td>0.912613</td>\n",
       "      <td>1.113668</td>\n",
       "      <td>0.371909</td>\n",
       "      <td>15.514423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>13</td>\n",
       "      <td>a winning animated feature that has something ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>17</td>\n",
       "      <td>the film sports a provocative and appealing st...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085227</td>\n",
       "      <td>0.030475</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.335227</td>\n",
       "      <td>9.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>14</td>\n",
       "      <td>an entertaining computer generated hyperrealis...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.014015</td>\n",
       "      <td>0.970833</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.154167</td>\n",
       "      <td>10.679167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael Booth</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Denver Post</td>\n",
       "      <td>As Lion King did before it, Toy Story revived ...</td>\n",
       "      <td>2007-05-03</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>40</td>\n",
       "      <td>as lion king did before it toy story revived t...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037870</td>\n",
       "      <td>0.013122</td>\n",
       "      <td>0.949009</td>\n",
       "      <td>1.060352</td>\n",
       "      <td>0.367403</td>\n",
       "      <td>26.572245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh      imdb     publication  \\\n",
       "0         Derek Adams      1  114709.0        Time Out   \n",
       "1         David Ansen      1  114709.0        Newsweek   \n",
       "2       Leonard Klady      1  114709.0         Variety   \n",
       "3  Jonathan Rosenbaum      1  114709.0  Chicago Reader   \n",
       "4       Michael Booth      1  114709.0     Denver Post   \n",
       "\n",
       "                                               quote review_date    rtid  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04  9559.0   \n",
       "1  A winning animated feature that has something ...  2008-08-18  9559.0   \n",
       "2  The film sports a provocative and appealing st...  2008-06-09  9559.0   \n",
       "3  An entertaining computer-generated, hyperreali...  2008-03-10  9559.0   \n",
       "4  As Lion King did before it, Toy Story revived ...  2007-05-03  9559.0   \n",
       "\n",
       "       title  quote_len                                                 qt  \\\n",
       "0  Toy story         24  so ingenious in concept design and execution t...   \n",
       "1  Toy story         13  a winning animated feature that has something ...   \n",
       "2  Toy story         17  the film sports a provocative and appealing st...   \n",
       "3  Toy story         14  an entertaining computer generated hyperrealis...   \n",
       "4  Toy story         40  as lion king did before it toy story revived t...   \n",
       "\n",
       "       ...       SPACE_prop  SYM_prop  VERB_prop  X_prop  pos_part_avg  \\\n",
       "0      ...           0.0000       0.0   0.200000     0.0      0.065510   \n",
       "1      ...           0.0000       0.0   0.153846     0.0      0.020833   \n",
       "2      ...           0.0000       0.0   0.055556     0.0      0.085227   \n",
       "3      ...           0.0625       0.0   0.187500     0.0      0.015152   \n",
       "4      ...           0.0000       0.0   0.139535     0.0      0.037870   \n",
       "\n",
       "   neg_part_avg  obj_part_avg  pos_part_sum  neg_part_sum  obj_part_sum  \n",
       "0      0.021877      0.912613      1.113668      0.371909     15.514423  \n",
       "1      0.000000      0.979167      0.187500      0.000000      8.812500  \n",
       "2      0.030475      0.884298      0.937500      0.335227      9.727273  \n",
       "3      0.014015      0.970833      0.166667      0.154167     10.679167  \n",
       "4      0.013122      0.949009      1.060352      0.367403     26.572245  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Evaluate the new predictors with different models.\n",
    "\n",
    "Does regularization help? Decision trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.639679252428 0.615069103879\n"
     ]
    }
   ],
   "source": [
    "X = rt[['pos_part_avg','neg_part_avg','obj_part_avg','quote_len']+[x for x in rt.columns if x.endswith('_prop')]]\n",
    "y = rt.fresh.values\n",
    "\n",
    "lr_scores = cross_val_score(LogisticRegression(), X, y, cv=10)\n",
    "print np.mean(lr_scores), rt.fresh.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = rt[['pos_part_avg','neg_part_avg','obj_part_avg',\n",
    "        'pos_part_sum','neg_part_sum','obj_part_sum',\n",
    "        'quote_len']+[x for x in rt.columns if x.endswith('_prop')]]\n",
    "\n",
    "ss = StandardScaler()\n",
    "Xn = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1250 candidates, totalling 6250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    4.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks       | elapsed:    9.9s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks       | elapsed:   17.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks       | elapsed:   27.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks       | elapsed:   39.6s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks       | elapsed:   51.4s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks       | elapsed:  1.1min\n",
      "[Parallel(n_jobs=1)]: Done 4049 tasks       | elapsed:  1.4min\n",
      "[Parallel(n_jobs=1)]: Done 4999 tasks       | elapsed:  1.7min\n",
      "[Parallel(n_jobs=1)]: Done 6049 tasks       | elapsed:  2.1min\n",
      "[Parallel(n_jobs=1)]: Done 6250 out of 6250 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['elasticnet'], 'loss': ['log'], 'l1_ratio': array([ 0.01   ,  0.05125,  0.0925 ,  0.13375,  0.175  ,  0.21625,\n",
       "        0.2575 ,  0.29875,  0.34   ,  0.38125,  0.4225 ,  0.46375,\n",
       "        0.505  ,  0.54625,  0.5875 ,  0.62875,  0.67   ,  0.71125,\n",
       "        0.7525 ,  0.79375,  0.8...    3.08884e+00,   3.90694e+00,   4.94171e+00,   6.25055e+00,\n",
       "         7.90604e+00,   1.00000e+01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_params = {\n",
    "    'loss':['log'],\n",
    "    'penalty':['elasticnet'],\n",
    "    'alpha':np.logspace(-4,1,50),\n",
    "    'l1_ratio':np.linspace(0.01,1.0,25)\n",
    "}\n",
    "\n",
    "sgd_gs = GridSearchCV(SGDClassifier(), sgd_params, cv=5, verbose=1)\n",
    "sgd_gs.fit(Xn, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'elasticnet', 'alpha': 0.0054286754393238594, 'loss': 'log', 'l1_ratio': 0.25750000000000001}\n"
     ]
    }
   ],
   "source": [
    "print sgd_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.644315648685\n"
     ]
    }
   ],
   "source": [
    "print sgd_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_part_avg 0.41936535519\n",
      "neg_part_avg -0.230345654405\n",
      "obj_part_avg 0.0\n",
      "pos_part_sum 0.144675979279\n",
      "neg_part_sum 0.0\n",
      "obj_part_sum 0.0\n",
      "quote_len 0.141753935347\n",
      "ADJ_prop 0.00439368864367\n",
      "ADP_prop 0.0\n",
      "ADV_prop -0.097246719695\n",
      "CONJ_prop 0.0921578255495\n",
      "DET_prop -0.051296444684\n",
      "INTJ_prop 0.0\n",
      "NOUN_prop 0.0464299458926\n",
      "NUM_prop 0.0\n",
      "PART_prop -0.128019386619\n",
      "PRON_prop 0.0894064877574\n",
      "PROPN_prop 0.0618345363725\n",
      "PUNCT_prop 0.0\n",
      "SPACE_prop 0.0\n",
      "SYM_prop 0.0\n",
      "VERB_prop -0.10001171179\n",
      "X_prop 0.0\n"
     ]
    }
   ],
   "source": [
    "#lr = LogisticRegression().fit(X, y)\n",
    "sgd_best = sgd_gs.best_estimator_\n",
    "for var, coef in zip(X.columns, sgd_best.coef_[0]):\n",
    "    print var, coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = rt[['pos_part_avg','neg_part_avg','obj_part_avg',\n",
    "        'pos_part_sum','neg_part_sum','obj_part_sum',\n",
    "        'quote_len']+['ADJ_prop','ADV_prop','CONJ_prop','DET_prop','NOUN_prop',\n",
    "                      'PART_prop','PRON_prop','PROPN_prop','VERB_prop']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 216 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.6s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    2.6s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks       | elapsed:    7.0s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks       | elapsed:   15.6s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks       | elapsed:   29.6s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks       | elapsed:   50.6s\n",
      "[Parallel(n_jobs=1)]: Done 2160 out of 2160 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_features': ['sqrt', 'log2', None], 'min_samples_split': [2, 4, 8, 16, 32, 64, 124, 256], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_params = {\n",
    "    'max_depth':[1,2,3,4,5,6,7,8,None],\n",
    "    'max_features':['sqrt','log2',None],\n",
    "    'min_samples_split':[2,4,8,16,32,64,124,256]\n",
    "}\n",
    "\n",
    "dtc_gs = GridSearchCV(DecisionTreeClassifier(), dtc_params, cv=10, verbose=1)\n",
    "dtc_gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': None, 'min_samples_split': 2, 'max_depth': 3}\n",
      "0.629781542577\n"
     ]
    }
   ],
   "source": [
    "print dtc_gs.best_params_\n",
    "print dtc_gs.best_score_\n",
    "dtc_best = dtc_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_part_avg 0.538993823507\n",
      "neg_part_avg 0.0312775260933\n",
      "obj_part_avg 0.0\n",
      "pos_part_sum 0.189424331195\n",
      "neg_part_sum 0.108052239792\n",
      "obj_part_sum 0.0\n",
      "quote_len 0.0\n",
      "ADJ_prop 0.0\n",
      "ADV_prop 0.132252079413\n",
      "CONJ_prop 0.0\n",
      "DET_prop 0.0\n",
      "NOUN_prop 0.0\n",
      "PART_prop 0.0\n",
      "PRON_prop 0.0\n",
      "PROPN_prop 0.0\n",
      "VERB_prop 0.0\n"
     ]
    }
   ],
   "source": [
    "for var, fi in zip(X.columns, dtc_best.feature_importances_):\n",
    "    print var, fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp = pd.DataFrame(dtc_best.predict_proba(X), columns=['rotten_prob','fresh_prob'])\n",
    "pp['ind'] = range(pp.shape[0])\n",
    "pp['quote'] = rt.quote.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.sort_values('rotten_prob', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limiting the gore, but not the carnage, in pursuit of a PG-13 rating and more youngsters, pic remains a cluttered, nasty exercise that seems principally intent on selling action figures.\n",
      "============================================================\n",
      "\n",
      "Sarah Thorpe's screenplay is a compendium of by-the-book cliches; Kaufman's direction leaves the material stranded in a limbo between po-faced and trashy; Judd's approximation of drunkenness is worrying to behold.\n",
      "============================================================\n",
      "\n",
      "This family comedy finds unearned laughs in old women and dog flatulence.\n",
      "============================================================\n",
      "\n",
      "Adequate in every way and oddly subversive in spots, but that's about it.\n",
      "============================================================\n",
      "\n",
      "A series of emotionally wrenching moments that made My Life as a Dog a transatlantic hit when it arrived in 1985.\n",
      "============================================================\n",
      "\n",
      "Movies like Hard Eight remind me of what original, compelling characters the movies can sometimes give us.\n",
      "============================================================\n",
      "\n",
      "There's something almost hypnotic about the way Hard Eight develops -- even in its slowest, most tedious moments, it keeps our attention.\n",
      "============================================================\n",
      "\n",
      "Noirish thrillers live or die by their plot twists and dialogue... Unfortunately, the script by first-time filmmaker Paul Thomas Anderson fails on both counts.\n",
      "============================================================\n",
      "\n",
      "Plays like a three-hour rough cut that's been trimmed down to a slightly shorter rough cut.\n",
      "============================================================\n",
      "\n",
      "Most film sequels are strictly optional. The Godfather Part III is inevitable, and as such it's irresistible.\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for quote in pp.quote[0:10]:\n",
    "    print quote\n",
    "    print '============================================================\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
